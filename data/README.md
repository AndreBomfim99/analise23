# ğŸ“Š Dados - Brazilian E-Commerce (Olist)

Este diretÃ³rio contÃ©m os dados brutos utilizados no projeto de anÃ¡lise do e-commerce brasileiro.

---

## ğŸ—‚ï¸ Estrutura de DiretÃ³rios
```
data/
â”œâ”€â”€ raw/                    # Dados brutos originais (CSV)
â”‚   â”œâ”€â”€ olist_customers_dataset.csv
â”‚   â”œâ”€â”€ olist_geolocation_dataset.csv
â”‚   â”œâ”€â”€ olist_order_items_dataset.csv
â”‚   â”œâ”€â”€ olist_order_payments_dataset.csv
â”‚   â”œâ”€â”€ olist_order_reviews_dataset.csv
â”‚   â”œâ”€â”€ olist_orders_dataset.csv
â”‚   â”œâ”€â”€ olist_products_dataset.csv
â”‚   â”œâ”€â”€ olist_sellers_dataset.csv
â”‚   â””â”€â”€ product_category_name_translation.csv
â””â”€â”€ processed/              # Dados processados (gerados pelo ETL)
```

---

## ğŸ“¥ Como Obter os Dados

### **OpÃ§Ã£o 1: Download Manual (Kaggle)**

1. Acesse: https://www.kaggle.com/datasets/olistbr/brazilian-ecommerce
2. Clique em **"Download"** (necessÃ¡rio login no Kaggle)
3. Extraia o arquivo `archive.zip`
4. Mova todos os arquivos `.csv` para `data/raw/`

### **OpÃ§Ã£o 2: Kaggle API (Recomendado)**
```bash
# 1. Instalar Kaggle CLI
pip install kaggle

# 2. Configurar credenciais
# Baixe kaggle.json em: https://www.kaggle.com/settings
# Mova para: ~/.kaggle/kaggle.json (Linux/Mac) ou C:\Users\<user>\.kaggle\kaggle.json (Windows)

# 3. Download automÃ¡tico
kaggle datasets download -d olistbr/brazilian-ecommerce -p data/raw/ --unzip
```

### **OpÃ§Ã£o 3: Script Python Automatizado**
```python
import kaggle
import os

# Autenticar (requer kaggle.json configurado)
kaggle.api.authenticate()

# Download dataset
kaggle.api.dataset_download_files(
    'olistbr/brazilian-ecommerce',
    path='data/raw/',
    unzip=True
)

print("âœ“ Dataset baixado com sucesso!")
```

---

## ğŸ“‹ DescriÃ§Ã£o dos Arquivos

| Arquivo | DescriÃ§Ã£o | Registros | Tamanho |
|---------|-----------|-----------|---------|
| **olist_orders_dataset.csv** | Pedidos principais | ~100k | ~5 MB |
| **olist_order_items_dataset.csv** | Itens dos pedidos | ~112k | ~15 MB |
| **olist_customers_dataset.csv** | Dados dos clientes | ~99k | ~5 MB |
| **olist_sellers_dataset.csv** | Vendedores | ~3k | ~200 KB |
| **olist_products_dataset.csv** | CatÃ¡logo de produtos | ~32k | ~2 MB |
| **olist_order_payments_dataset.csv** | Pagamentos | ~103k | ~5 MB |
| **olist_order_reviews_dataset.csv** | AvaliaÃ§Ãµes | ~99k | ~35 MB |
| **olist_geolocation_dataset.csv** | GeolocalizaÃ§Ã£o | ~1M | ~50 MB |
| **product_category_name_translation.csv** | TraduÃ§Ã£o categorias | 71 | ~2 KB |

**Total:** ~117 MB (comprimido: ~35 MB)

---

## ğŸ”’ Integridade dos Dados

ApÃ³s o download, valide a integridade:
```bash
# Verificar arquivos presentes
ls -lh data/raw/*.csv

# Contar registros (Linux/Mac)
wc -l data/raw/*.csv

# Verificar primeiras linhas
head data/raw/olist_orders_dataset.csv
```

**Checksums esperados (MD5):**
```
olist_orders_dataset.csv: a1b2c3d4e5f6...
olist_customers_dataset.csv: f6e5d4c3b2a1...
# ... (adicionar checksums reais se necessÃ¡rio)
```

---

## ğŸš¨ Importante

- **NÃƒO commitar dados brutos** no Git (`.gitignore` jÃ¡ configurado)
- Dados processados vÃ£o para `processed/` (gerados pelo ETL)
- Dados sensÃ­veis (se houver) devem ser anonimizados
- Dataset original: Â© Olist (uso educacional/pesquisa)

---

## ğŸ“Š Schema das Tabelas

### **Relacionamentos:**
```
orders (order_id) â”€â”€â”¬â”€â”€â†’ order_items (order_id)
                    â”œâ”€â”€â†’ order_payments (order_id)
                    â”œâ”€â”€â†’ order_reviews (order_id)
                    â””â”€â”€â†’ customers (customer_id)

order_items (product_id) â”€â”€â†’ products (product_id)
order_items (seller_id) â”€â”€â†’ sellers (seller_id)

customers (customer_zip_code) â”€â”€â†’ geolocation (zip_code)
sellers (seller_zip_code) â”€â”€â†’ geolocation (zip_code)
```

### **Principais Colunas:**

**orders:**
- `order_id` (PK)
- `customer_id` (FK)
- `order_status`
- `order_purchase_timestamp`
- `order_delivered_customer_date`
- `order_estimated_delivery_date`

**order_items:**
- `order_id` (FK)
- `product_id` (FK)
- `seller_id` (FK)
- `price`
- `freight_value`

**customers:**
- `customer_id` (PK)
- `customer_unique_id`
- `customer_zip_code`
- `customer_city`
- `customer_state`

---

## ğŸ”§ PrÃ³ximos Passos

ApÃ³s baixar os dados:

1. **Validar integridade:** `python scripts/validate_data.py`
2. **Executar ETL:** `docker-compose up etl`
3. **Carregar no BigQuery:** `python python/etl/load_to_bigquery.py`
4. **Iniciar anÃ¡lises:** Abrir notebooks em `notebooks/`

---

## ğŸ“š ReferÃªncias

- **Fonte Original:** [Kaggle - Olist Brazilian E-Commerce](https://www.kaggle.com/datasets/olistbr/brazilian-ecommerce)
- **DocumentaÃ§Ã£o Olist:** [Olist Store](https://olist.com/)
- **Paper AcadÃªmico:** [E-Commerce Analysis Paper](https://arxiv.org/...)

---

## â“ Problemas Comuns

**Erro: "Dataset not found"**
- Verifique credenciais Kaggle (`kaggle.json`)
- Confirme permissÃµes do dataset

**Erro: "Permission denied"**
- Ajuste permissÃµes: `chmod 600 ~/.kaggle/kaggle.json`

**Arquivos corrompidos:**
- Re-download: `kaggle datasets download ... --force`

---

**âœ… Dados prontos?** Prossiga para: [ConfiguraÃ§Ã£o do Ambiente](../README.md#setup)