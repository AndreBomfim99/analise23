# ğŸ—ï¸ Arquitetura do Projeto - Olist E-Commerce Analysis

DocumentaÃ§Ã£o tÃ©cnica da arquitetura end-to-end do projeto de anÃ¡lise de dados.

---

## ğŸ“‹ Ãndice

1. [VisÃ£o Geral](#visao-geral)
2. [Arquitetura de Alto NÃ­vel](#arquitetura-alto-nivel)
3. [Camadas da Arquitetura](#camadas)
4. [Fluxo de Dados](#fluxo-dados)
5. [Tecnologias Utilizadas](#tecnologias)
6. [Modelo de Dados](#modelo-dados)
7. [Infraestrutura](#infraestrutura)
8. [SeguranÃ§a](#seguranca)
9. [Escalabilidade](#escalabilidade)

---

## ğŸ¯ VisÃ£o Geral {#visao-geral}

Projeto de anÃ¡lise de dados de e-commerce implementando arquitetura moderna de Data Analytics com pipeline ETL, data warehouse na nuvem e dashboards interativos.

**CaracterÃ­sticas:**
- âœ… Arquitetura serverless (Cloud-native)
- âœ… Pipeline ETL automatizado
- âœ… Data warehouse escalÃ¡vel (BigQuery)
- âœ… AnÃ¡lises reprodutÃ­veis (Docker + Notebooks)
- âœ… VisualizaÃ§Ãµes interativas (Looker Studio)

---

## ğŸ›ï¸ Arquitetura de Alto NÃ­vel {#arquitetura-alto-nivel}
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          DATA SOURCES                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â”‚ Raw CSV Files
                                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       INGESTION LAYER                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  â”‚   Kaggle     â”‚â”€â”€â–¶â”‚ Python ETL   â”‚â”€â”€â–¶â”‚   Docker     â”‚           â”‚
â”‚  â”‚   Dataset    â”‚   â”‚  (pandas)    â”‚   â”‚  Container   â”‚           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â”‚ Structured Data
                                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      STORAGE LAYER                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚            Google BigQuery (Data Warehouse)            â”‚         â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚         â”‚
â”‚  â”‚  â”‚  orders  â”‚ â”‚customers â”‚ â”‚ products â”‚ â”‚ payments â”‚ â”‚         â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚         â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚         â”‚
â”‚  â”‚  â”‚  sellers â”‚ â”‚  reviews â”‚ â”‚  items   â”‚ â”‚geolocationâ”‚ â”‚        â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â”‚ SQL Queries
                                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    TRANSFORMATION LAYER                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  â”‚   Staging    â”‚â”€â”€â–¶â”‚  Analytics   â”‚â”€â”€â–¶â”‚ Materialized â”‚           â”‚
â”‚  â”‚    Views     â”‚   â”‚   Queries    â”‚   â”‚    Views     â”‚           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚                           â”‚
                    â–¼                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     ANALYTICS LAYER         â”‚   â”‚   PRESENTATION LAYER        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚   â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  Jupyter Notebooks â”‚     â”‚   â”‚  â”‚  Looker Studio     â”‚    â”‚
â”‚  â”‚  - Cohort Analysis â”‚     â”‚   â”‚  â”‚  - Executive       â”‚    â”‚
â”‚  â”‚  - RFM Segment     â”‚     â”‚   â”‚  â”‚  - Customer        â”‚    â”‚
â”‚  â”‚  - LTV Analysis    â”‚     â”‚   â”‚  â”‚  - Product         â”‚    â”‚
â”‚  â”‚  - Category Perf   â”‚     â”‚   â”‚  â”‚  - Logistics       â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚   â”‚  â”‚  - Financial       â”‚    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚   â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚  â”‚  Python Scripts    â”‚     â”‚   â”‚                             â”‚
â”‚  â”‚  - rfm_seg.py      â”‚     â”‚   â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  - cohort_analysis â”‚     â”‚   â”‚  â”‚   Screenshots      â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚   â”‚  â”‚   + Export PDF     â”‚    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
                                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                              â”‚
                                              â–¼
                                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                    â”‚   End Users       â”‚
                                    â”‚  (Web Browser)    â”‚
                                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”„ Camadas da Arquitetura {#camadas}

### **1. Data Sources Layer**

**Fonte:** Kaggle - Brazilian E-Commerce Dataset (Olist)
```yaml
Formato: CSV files
Volume: ~117 MB (comprimido: ~35 MB)
PerÃ­odo: 2016-09 a 2018-08 (24 meses)
Registros: ~100k pedidos

Arquivos:
  - olist_orders_dataset.csv (99,441 registros)
  - olist_customers_dataset.csv (99,441 registros)
  - olist_order_items_dataset.csv (112,650 registros)
  - olist_products_dataset.csv (32,951 registros)
  - olist_sellers_dataset.csv (3,095 registros)
  - olist_order_payments_dataset.csv (103,886 registros)
  - olist_order_reviews_dataset.csv (99,224 registros)
  - olist_geolocation_dataset.csv (1,000,163 registros)
  - product_category_name_translation.csv (71 registros)
```

---

### **2. Ingestion Layer (ETL)**

**Pipeline ETL em Python:**
```python
# Componentes
Componentes:
â”œâ”€â”€ extract_kaggle.py       # Download automÃ¡tico via Kaggle API
â”œâ”€â”€ load_to_bigquery.py     # Carga para BigQuery
â””â”€â”€ data_validation.py      # ValidaÃ§Ã£o de qualidade

Tecnologias:
- Python 3.11+
- pandas 2.0+
- google-cloud-bigquery 3.10+
- Docker 24+

CaracterÃ­sticas:
âœ“ Idempotente (reruns seguros)
âœ“ ValidaÃ§Ã£o de schema
âœ“ Tratamento de erros
âœ“ Logging estruturado
âœ“ Containerizado (Docker)
```

**Fluxo ETL:**
```
1. EXTRACT
   â””â”€ Kaggle API â†’ Download CSVs â†’ data/raw/

2. TRANSFORM
   â”œâ”€ Validar schema
   â”œâ”€ Remover duplicatas
   â”œâ”€ Tratar valores nulos
   â”œâ”€ Converter tipos de dados
   â””â”€ Calcular mÃ©tricas derivadas

3. LOAD
   â”œâ”€ Criar dataset BigQuery
   â”œâ”€ Definir schemas
   â”œâ”€ Carregar tabelas (batch)
   â””â”€ Validar integridade referencial
```

---

### **3. Storage Layer (Data Warehouse)**

**Google BigQuery:**
```sql
-- ConfiguraÃ§Ã£o
Project: your-gcp-project
Dataset: olist_ecommerce
Region: US (multi-region)
Storage: ~500 MB
Partitioning: DATE(order_purchase_timestamp)

Tabelas (8):
â”œâ”€â”€ orders              # 99k rows
â”œâ”€â”€ customers           # 99k rows
â”œâ”€â”€ order_items         # 112k rows
â”œâ”€â”€ products            # 32k rows
â”œâ”€â”€ sellers             # 3k rows
â”œâ”€â”€ payments            # 103k rows
â”œâ”€â”€ reviews             # 99k rows
â””â”€â”€ geolocation         # 1M rows

Views Customizadas:
â”œâ”€â”€ rfm_segments        # SegmentaÃ§Ã£o RFM prÃ©-calculada
â”œâ”€â”€ cohort_retention    # Matriz de retenÃ§Ã£o
â”œâ”€â”€ category_performance # Performance por categoria
â””â”€â”€ delivery_metrics    # MÃ©tricas de entrega
```

**OtimizaÃ§Ãµes:**
```sql
-- 1. Particionamento
CREATE TABLE orders
PARTITION BY DATE(order_purchase_timestamp)
CLUSTER BY customer_state, order_status;

-- 2. Views Materializadas
CREATE MATERIALIZED VIEW rfm_segments AS
SELECT 
  customer_unique_id,
  recency, frequency, monetary,
  rfm_score, segment
FROM rfm_calculation;

-- 3. Clustering
CLUSTER BY customer_state, product_category_name;
```

---

### **4. Transformation Layer (SQL)**

**Estrutura:**
```
sql/
â”œâ”€â”€ 01_schema/
â”‚   â”œâ”€â”€ create_tables_bigquery.sql    # DDL: Criar tabelas
â”‚   â””â”€â”€ create_views.sql              # Views auxiliares
â”‚
â”œâ”€â”€ 02_transformations/
â”‚   â”œâ”€â”€ staging_orders.sql            # Staging: Orders
â”‚   â”œâ”€â”€ staging_customers.sql         # Staging: Customers
â”‚   â””â”€â”€ mart_customer_metrics.sql     # Mart: MÃ©tricas agregadas
â”‚
â””â”€â”€ 03_analytics/
    â”œâ”€â”€ ltv_analysis.sql              # Lifetime Value
    â”œâ”€â”€ cohort_retention.sql          # Cohort Analysis
    â”œâ”€â”€ rfm_segmentation.sql          # RFM Segments
    â”œâ”€â”€ category_performance.sql      # Categorias
    â””â”€â”€ delivery_analysis.sql         # LogÃ­stica
```

**PadrÃ£o Medallion Architecture:**
```
Bronze (Raw)          Silver (Staging)         Gold (Analytics)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€     â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€      â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
olist_orders     â”€â”€â–¶  staging_orders      â”€â”€â–¶  mart_customer_ltv
olist_customers  â”€â”€â–¶  staging_customers   â”€â”€â–¶  mart_rfm_segments
olist_payments   â”€â”€â–¶  staging_payments    â”€â”€â–¶  mart_cohort_retention
```

---

### **5. Analytics Layer**

**Jupyter Notebooks:**
```
notebooks/
â”œâ”€â”€ 01_exploratory_analysis.ipynb     # EDA inicial
â”œâ”€â”€ 02_ltv_deep_dive.ipynb            # LTV detalhado
â”œâ”€â”€ 03_cohort_retention.ipynb         # RetenÃ§Ã£o
â”œâ”€â”€ 04_rfm_segmentation.ipynb         # SegmentaÃ§Ã£o RFM
â””â”€â”€ 05_category_performance.ipynb     # Categorias
```

**Python Scripts:**
```
python/analytics/
â”œâ”€â”€ ltv_calculator.py                 # Scripts programÃ¡ticos
â”œâ”€â”€ cohort_analysis.py
â”œâ”€â”€ rfm_segmentation.py
â””â”€â”€ category_performance.py
```

**AnÃ¡lises Implementadas:**

| AnÃ¡lise | MÃ©todo | Output |
|---------|--------|--------|
| **Cohort Retention** | Matriz retenÃ§Ã£o + curvas | PNG + CSV |
| **RFM Segmentation** | Quintis + regras negÃ³cio | CSV + segments |
| **LTV Analysis** | Cohort-based LTV | MÃ©tricas por estado |
| **Category Performance** | Pareto + temporal | Insights + grÃ¡ficos |
| **Delivery Analysis** | CorrelaÃ§Ã£o atraso-NPS | Rotas problemÃ¡ticas |

---

### **6. Presentation Layer**

**Looker Studio Dashboards:**
```
Dashboards (5):
â”œâ”€â”€ Executive Dashboard          # KPIs alto nÃ­vel
â”œâ”€â”€ Customer Analytics           # LTV, Cohort, RFM
â”œâ”€â”€ Product Performance          # Categorias, Pareto
â”œâ”€â”€ Logistics Overview           # SLA, entregas
â””â”€â”€ Financial Deep Dive          # Receita, pagamentos

CaracterÃ­sticas:
âœ“ ConexÃ£o direta BigQuery
âœ“ Filtros interativos
âœ“ Auto-refresh (12h cache)
âœ“ ExportÃ¡vel (PDF/CSV)
âœ“ Mobile-friendly
```

---

## ğŸ”„ Fluxo de Dados Detalhado {#fluxo-dados}

### **Pipeline Completo (End-to-End)**
```
FASE 1: INGEST (T+0h)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Kaggle Dataset
    â”‚
    â”œâ”€â–¶ kaggle datasets download
    â”‚
    â–¼
data/raw/*.csv (117 MB)
    â”‚
    â”œâ”€â–¶ Python ETL
    â”‚   â”œâ”€â”€ Validation
    â”‚   â”œâ”€â”€ Type Conversion
    â”‚   â””â”€â”€ Deduplication
    â”‚
    â–¼
BigQuery Tables (8 tabelas)


FASE 2: TRANSFORM (T+0.5h)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
BigQuery Tables
    â”‚
    â”œâ”€â–¶ SQL: 01_schema/*.sql
    â”‚   â””â”€â”€ CREATE TABLES, VIEWS
    â”‚
    â”œâ”€â–¶ SQL: 02_transformations/*.sql
    â”‚   â”œâ”€â”€ staging_orders
    â”‚   â”œâ”€â”€ staging_customers
    â”‚   â””â”€â”€ mart_customer_metrics
    â”‚
    â”œâ”€â–¶ SQL: 03_analytics/*.sql
    â”‚   â”œâ”€â”€ ltv_analysis
    â”‚   â”œâ”€â”€ cohort_retention
    â”‚   â”œâ”€â”€ rfm_segmentation
    â”‚   â”œâ”€â”€ category_performance
    â”‚   â””â”€â”€ delivery_analysis
    â”‚
    â–¼
Analytical Views (5 views)


FASE 3: ANALYZE (T+1h)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Analytical Views
    â”‚
    â”œâ”€â–¶ Jupyter Notebooks
    â”‚   â”œâ”€â”€ Load data from BigQuery
    â”‚   â”œâ”€â”€ Advanced Analytics
    â”‚   â”œâ”€â”€ Statistical Tests
    â”‚   â””â”€â”€ Generate Visualizations
    â”‚
    â–¼
Insights + Images (docs/images/)


FASE 4: VISUALIZE (T+1.5h)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
BigQuery + Views
    â”‚
    â”œâ”€â–¶ Looker Studio
    â”‚   â”œâ”€â”€ Connect to BigQuery
    â”‚   â”œâ”€â”€ Build Charts
    â”‚   â”œâ”€â”€ Apply Filters
    â”‚   â””â”€â”€ Publish Dashboards
    â”‚
    â–¼
Interactive Dashboards (5 dashboards)
    â”‚
    â””â”€â–¶ End Users (Browser)
```

---

## ğŸ’» Tecnologias Utilizadas {#tecnologias}

### **Stack Completo**

| Camada | Tecnologia | VersÃ£o | Uso |
|--------|-----------|--------|-----|
| **Data Source** | Kaggle Dataset | - | Fonte de dados |
| **Ingestion** | Python | 3.11+ | ETL scripts |
| **Ingestion** | pandas | 2.0+ | Data manipulation |
| **Ingestion** | Docker | 24+ | ContainerizaÃ§Ã£o |
| **Storage** | Google BigQuery | - | Data Warehouse |
| **Transform** | SQL | - | Data transformation |
| **Analytics** | Jupyter | 1.0+ | Interactive analysis |
| **Analytics** | Python | 3.11+ | Statistical analysis |
| **Analytics** | scipy | 1.10+ | CorrelaÃ§Ãµes |
| **Analytics** | matplotlib | 3.7+ | VisualizaÃ§Ãµes |
| **Analytics** | seaborn | 0.12+ | VisualizaÃ§Ãµes |
| **Presentation** | Looker Studio | - | Dashboards |
| **Version Control** | Git/GitHub | - | Code versioning |
| **Documentation** | Markdown | - | Documentation |

---

### **DependÃªncias Python**
```txt
# Core
pandas>=2.0.0
numpy>=1.24.0
google-cloud-bigquery>=3.10.0
python-dotenv>=1.0.0

# Analytics
scipy>=1.10.0
scikit-learn>=1.3.0
matplotlib>=3.7.0
seaborn>=0.12.0

# Jupyter
jupyter>=1.0.0
ipykernel>=6.25.0

# Dev/Test
pytest>=7.4.0
pytest-cov>=4.1.0
```

---

## ğŸ—„ï¸ Modelo de Dados {#modelo-dados}

### **Entity Relationship Diagram (ERD)**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    customers    â”‚
â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
â”‚ customer_id (PK)â”‚â—€â”€â”€â”€â”€â”
â”‚ customer_unique â”‚     â”‚
â”‚ customer_state  â”‚     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
                        â”‚
                        â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚     orders      â”‚     â”‚
â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚     â”‚
â”‚ order_id (PK)   â”‚     â”‚
â”‚ customer_id (FK)â”‚â”€â”€â”€â”€â”€â”˜
â”‚ order_status    â”‚
â”‚ purchase_date   â”‚â—€â”€â”€â”€â”€â”
â”‚ delivered_date  â”‚     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
         â”‚              â”‚
         â”‚              â”‚
         â”‚              â”‚
    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”
    â”‚         â”‚    â”‚         â”‚
    â–¼         â–¼    â–¼         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚order_   â”‚ â”‚order_   â”‚ â”‚order_   â”‚
â”‚items    â”‚ â”‚payments â”‚ â”‚reviews  â”‚
â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚ â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚ â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
â”‚order_id â”‚ â”‚order_id â”‚ â”‚order_id â”‚
â”‚product_ â”‚ â”‚payment_ â”‚ â”‚review_  â”‚
â”‚seller_idâ”‚ â”‚type     â”‚ â”‚score    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  products   â”‚
â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
â”‚ product_id  â”‚
â”‚ category    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    
    
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   sellers   â”‚
â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
â”‚ seller_id   â”‚
â”‚ seller_stateâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### **Tabelas e Relacionamentos**

**1. customers (99k registros)**
```sql
customer_id (PK)              STRING
customer_unique_id            STRING
customer_zip_code_prefix      STRING
customer_city                 STRING
customer_state                STRING
```

**2. orders (99k registros)**
```sql
order_id (PK)                     STRING
customer_id (FK â†’ customers)      STRING
order_status                      STRING
order_purchase_timestamp          TIMESTAMP
order_approved_at                 TIMESTAMP
order_delivered_carrier_date      TIMESTAMP
order_delivered_customer_date     TIMESTAMP
order_estimated_delivery_date     TIMESTAMP
```

**3. order_items (112k registros)**
```sql
order_id (FK â†’ orders)        STRING
order_item_id                 INTEGER
product_id (FK â†’ products)    STRING
seller_id (FK â†’ sellers)      STRING
shipping_limit_date           TIMESTAMP
price                         FLOAT
freight_value                 FLOAT
```

**4. products (32k registros)**
```sql
product_id (PK)                   STRING
product_category_name             STRING
product_name_length               INTEGER
product_description_length        INTEGER
product_photos_qty                INTEGER
product_weight_g                  INTEGER
product_length_cm                 INTEGER
product_height_cm                 INTEGER
product_width_cm                  INTEGER
```

**5. sellers (3k registros)**
```sql
seller_id (PK)                STRING
seller_zip_code_prefix        STRING
seller_city                   STRING
seller_state                  STRING
```

**6. order_payments (103k registros)**
```sql
order_id (FK â†’ orders)        STRING
payment_sequential            INTEGER
payment_type                  STRING
payment_installments          INTEGER
payment_value                 FLOAT
```

**7. order_reviews (99k registros)**
```sql
review_id (PK)                STRING
order_id (FK â†’ orders)        STRING
review_score                  INTEGER
review_comment_title          STRING
review_comment_message        STRING
review_creation_date          TIMESTAMP
review_answer_timestamp       TIMESTAMP
```

**8. geolocation (1M registros)**
```sql
geolocation_zip_code_prefix   STRING
geolocation_lat               FLOAT
geolocation_lng               FLOAT
geolocation_city              STRING
geolocation_state             STRING
```

---

### **Cardinalidade dos Relacionamentos**
```
customers (1) â”€â”€< orders (N)
orders (1) â”€â”€< order_items (N)
orders (1) â”€â”€< order_payments (N)
orders (1) â”€â”€< order_reviews (N)
products (1) â”€â”€< order_items (N)
sellers (1) â”€â”€< order_items (N)
```

---

## ğŸ¢ Infraestrutura {#infraestrutura}

### **Ambiente de Desenvolvimento**
```yaml
Local Development:
  OS: Linux/MacOS/Windows
  Python: 3.11+
  Docker: 24+
  Git: 2.40+
  IDE: VSCode/PyCharm/Jupyter Lab
  
Dependencies:
  - virtualenv (ambiente Python isolado)
  - Docker Compose (orquestraÃ§Ã£o containers)
  - Kaggle CLI (download datasets)
```

---

### **Google Cloud Platform**
```yaml
Services Used:
  - BigQuery: Data Warehouse
  - Cloud Storage: Backup opcional
  - IAM: Gerenciamento de acesso
  - Cloud Scheduler: AutomaÃ§Ã£o (opcional)
  
Billing:
  - BigQuery Free Tier: 1TB queries/mÃªs
  - Storage Free Tier: 10GB
  - Custo estimado: $0-5/mÃªs (free tier)
```

---

### **ContainerizaÃ§Ã£o (Docker)**
```dockerfile
# Dockerfile
FROM python:3.11-slim

WORKDIR /app

COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY . .

CMD ["python", "python/etl/load_to_bigquery.py"]
```
```yaml
# docker-compose.yml
version: '3.8'

services:
  etl:
    build: .
    env_file: .env
    volumes:
      - ./data:/app/data
      - ./keys:/app/keys
    command: python python/etl/load_to_bigquery.py
  
  jupyter:
    build: .
    ports:
      - "8888:8888"
    volumes:
      - ./notebooks:/app/notebooks
    command: jupyter lab --ip=0.0.0.0 --allow-root
```

---

## ğŸ”’ SeguranÃ§a {#seguranca}

### **AutenticaÃ§Ã£o e AutorizaÃ§Ã£o**
```yaml
Google Cloud (IAM):
  Service Account:
    - Nome: ecommerce-etl-sa
    - Roles:
      - BigQuery Data Editor
      - BigQuery Job User
      - BigQuery Read Session User
  
  Credentials:
    - Tipo: JSON key file
    - LocalizaÃ§Ã£o: keys/gcp-key.json
    - Git: .gitignore (nÃ£o commitar)
```

---

### **Dados SensÃ­veis**
```yaml
PII (Personally Identifiable Information):
  Masking:
    - customer_id: Hash MD5
    - order_id: Ãšltimos 4 dÃ­gitos apenas
    - email: NÃ£o disponÃ­vel no dataset
  
  Acesso:
    - ProduÃ§Ã£o: Row-level security
    - Desenvolvimento: Dados anonimizados
    - Dashboards pÃºblicos: Agregados apenas
```

---

### **Boas PrÃ¡ticas**
```bash
âœ“ Credenciais em .env (nunca hardcoded)
âœ“ Service accounts com menor privilÃ©gio
âœ“ Secrets nÃ£o versionados (gitignore)
âœ“ HTTPS apenas para APIs
âœ“ Audit logs habilitados
âœ“ Backup regular dos dados

âœ— NÃ£o commitar keys/tokens
âœ— NÃ£o expor BigQuery publicamente
âœ— NÃ£o usar credenciais pessoais em produÃ§Ã£o
```

---

## ğŸ“ˆ Escalabilidade {#escalabilidade}

### **Dimensionamento Vertical**
```yaml
BigQuery:
  Storage: EscalÃ¡vel automaticamente
  Compute: On-demand, pago por query
  Limits:
    - 1000 concurrent queries
    - 6 hours max query time
    - 100TB max table size
```

---

### **OtimizaÃ§Ãµes de Performance**
```sql
-- 1. Particionamento
CREATE TABLE orders
PARTITION BY DATE(order_purchase_timestamp)
OPTIONS(
  partition_expiration_days=730,
  require_partition_filter=true
);

-- 2. Clustering
CREATE TABLE orders
PARTITION BY DATE(order_purchase_timestamp)
CLUSTER BY customer_state, order_status;

-- 3. Materialized Views
CREATE MATERIALIZED VIEW daily_metrics
OPTIONS(
  enable_refresh=true,
  refresh_interval_minutes=60
) AS
SELECT 
  DATE(order_purchase_timestamp) as date,
  COUNT(*) as orders,
  SUM(payment_value) as revenue
FROM orders
GROUP BY date;
```

---

### **EstratÃ©gia de Crescimento**
```yaml
CenÃ¡rio Atual (100k pedidos):
  - Storage: ~500 MB
  - Query cost: ~$0/mÃªs (free tier)
  - ETL time: ~5 min
  
CenÃ¡rio 1M pedidos (10x):
  - Storage: ~5 GB
  - Query cost: ~$5/mÃªs
  - ETL time: ~30 min
  - SoluÃ§Ã£o: Batch processing, incremental loads
  
CenÃ¡rio 10M pedidos (100x):
  - Storage: ~50 GB
  - Query cost: ~$50/mÃªs
  - ETL time: ~3 hours
  - SoluÃ§Ã£o: Airflow, Spark, streaming ETL
```

---

## ğŸ”„ CI/CD e AutomaÃ§Ã£o

### **Pipeline Automatizado (Futuro)**
```yaml
GitHub Actions Workflow:
  Trigger: Push to main
  Steps:
    1. Run tests (pytest)
    2. Validate SQL syntax
    3. Deploy to BigQuery (staging)
    4. Run data quality checks
    5. Deploy to BigQuery (production)
    6. Refresh dashboards
    7. Send notification (Slack/Email)
```

---

## ğŸ“Š Monitoramento
```yaml
MÃ©tricas Monitoradas:
  - ETL success rate
  - Query performance (p50, p90, p95)
  - Storage size
  - Costs (BigQuery billing)
  - Dashboard usage (GA)
  - Data freshness
  
Alertas:
  - ETL failure â†’ Email
  - Query cost > $50/mÃªs â†’ Email
  - Data lag > 24h â†’ Slack
```

---

## ğŸ“š ReferÃªncias

- **BigQuery Docs:** https://cloud.google.com/bigquery/docs
- **Looker Studio:** https://support.google.com/looker-studio
- **Docker:** https://docs.docker.com/
- **pandas:** https://pandas.pydata.org/docs/
- **Kaggle API:** https://github.com/Kaggle/kaggle-api

---

## ğŸ”— Links Relacionados

- **RepositÃ³rio GitHub:** https://github.com/AndreBomfim99/analise23
- **Dashboards:** [looker_studio_links.md](../dashboards/looker_studio_links.md)
- **Metodologia:** [methodology.md](methodology.md)
- **Business Insights:** [business_insights.md](business_insights.md)

---

**Ãšltima atualizaÃ§Ã£o:** Novembro 2024  
**VersÃ£o:** 1.0  
**Autor:** AndrÃ© Bomfim